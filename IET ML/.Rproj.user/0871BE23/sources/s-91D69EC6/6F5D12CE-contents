# 
#  install.packages("ipred",dependencies=TRUE)
# # 
# # #other option
#  install.packages("mboost", dependencies=c("Depends", "Suggests"))

library(caret)
library(arm)
library(mboost)
library(klaR)
library (ipred)
library(nnet)
library(writexl)
library(readr)


subcarrierspacing <- read_csv("subcarrierspacing02.csv")
#View(subcarrierspacing)
# attach the iris dataset to the environment
#data(subcarrierspacing)

# rename the dataset
dataset <- subcarrierspacing
# 
# # define the filename
# filename <- "iris.csv"
# 
# # load the CSV file from the local directory
# dataset <- read.csv(filename, header=FALSE)
# 
# # set the column names in the dataset
# colnames(dataset) <- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
predict <- Spacing~.
# create a list of 80% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(dataset$Spacing, p=0.80, list=FALSE)

# select 20% of the data for validation
validation <- dataset[-validation_index,]

# use the remaining 80% of data to training and testing the models
dataset <- dataset[validation_index,]

#dimension of dataset
dim(dataset) #120 instances (rows) 5 attributes (column)

# list types for each attribute
sapply(dataset, class) #factor is nominal data. levels. ranking.

# take a peek at the first 5 rows of the data
head(dataset)
tail(dataset)

# list the levels for the class
levels(dataset$Spacing)

# summarize the class distribution
percentage <- prop.table(table(dataset$Spacing)) * 100
cbind(freq=table(dataset$Spacing), percentage=percentage)

summary(dataset)

#split numeric and factor. input and target
x <- dataset[,1:4]
y <- dataset[,5]


# boxplot for each attribute on one image
par(mfrow=c(1,9))
for(i in 1:9) {
  boxplot(x[,i], main=names(subcarrierspacing)[i])
}


par(mfrow = c(1,1))
plot(y)

# scatterplot matrix
featurePlot(x=x, y=y, plot="ellipse")

# box and whisker plots for each attribute
featurePlot(x=x, y=y, plot="box")

# density plots for each attribute by class value
scales <- list(x=list(relation="free"), y=list(relation="free"))
featurePlot(x=x, y=y, plot="density", scales=scales)

# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- c("Accuracy")

# a) linear algorithms
set.seed(100)
tunegridlda= expand.grid(dimen=c(0:5))
fit.lda <- train(predict, 
                 data=dataset,
                 method="lda2",
                 tuneGrid= tunegridlda,
                 metric=metric, 
                 trControl=control)

# b) nonlinear algorithms
# CART
set.seed(100)
#tunegridcart= expand.grid(cp=c(seq(0, 1, by=0.05)))
fit.cart <- train(predict, 
                  data=dataset, 
                  method="rpart",
                  tuneGrid = tunegridcart,
                  metric=metric, 
                  trControl=control)
# CART2
set.seed(100)
#tunegridcart2= expand.grid(maxdepth=c(0:5))
fit.cart2 <- train(predict, 
                   data=dataset, 
                   method="rpart2",
                   tuneGrid = tunegridcart2,
                   metric=metric, 
                   trControl=control)
# kNN
set.seed(100)
tunegridknn= expand.grid(k=c(1:50))
fit.knn <- train(predict,
                 data=dataset, 
                 method="knn", 
                 metric=metric, 
                 tuneGrid= tunegridknn,
                 trControl=control)

# c) advanced algorithms
# SVM
set.seed(100)
tunegridSVM = expand.grid(sigma= 2^c(-25, -20, -15,-10, -5, 0), C=3**(-7:7))
fit.svm <- train(predict,
                 data=dataset, 
                 method="svmRadial",
                 metric=metric, 
                 tuneGrid = tunegridSVM,
                 trControl=control)
plot(fit.svm, scales=list(x=list(log=3)))


# Random Forest
set.seed(100)
tunegridRF = expand.grid(mtry = seq(0, 200, by=1))
fit.rf <- train(predict, data=dataset,
                method="rf",
                metric = metric, 
                tuneGrid = tunegridRF,
                trControl = control)

# Bayesian Generalized Linear Model
set.seed(100)
fit.bayesglm <- train(predict, 
                      data=dataset, 
                      method="bayesglm",
                      metric=metric, 
                      trControl=control)


# Boosted Tree 
set.seed(100)
#tunegridbstTree = expand.grid(mstop = c(50,100,200,500), maxdepth = 1:4, nu = c(0.1, 0.01, 0.001,0.0001))
fit.bstTree <- train(predict,
                     data=dataset,
                     method="bstTree", 
                     tuneGrid = tunegridbstTree,
                     metric=metric,
                     trControl=control)

# Naive Bayes 
set.seed(100)
tunegridnb = expand.grid(fL=c(seq(0, 5, by = 0.25)),usekernel= c(TRUE,FALSE), adjust=c(seq(0, 5, by = 1)))
fit.nb <- train(predict,
                data=dataset,
                method="nb", 
                metric=metric,
                tuneGrid=tunegridnb,
                preProc = c("BoxCox", "center", "scale", "pca"),
                trControl=control)

# Multi-Layer Perceptron
set.seed(100)
tunegridmlp= expand.grid(size=c(0:500))
fit.mlp <- train(predict,
                 data = dataset, 
                 method="mlp",
                 metric=metric, 
                 tuneGrid=tunegridmlp,
                 trControl=control)

# multinomial logistic regression 
set.seed(100)
tunegridmultinom = expand.grid(decay=c(10,1,0.1, 0.01, 0.001,0.0001,0.00001,0.000001))
fit.glm <- train(predict,
                 data = dataset, 
                 method="multinom",
                 metric=metric, 
                 tuneGrid=tunegridmultinom,
                 trControl=control)
#############################################################################################################
#############################################################################################################


#summarize accuracy of models
results <- resamples(list(lda=fit.lda,
                          cart=fit.cart,
                          cart2=fit.cart2,
                          knn=fit.knn,
                          svm=fit.svm,
                          rf=fit.rf,
                          bayesglm=fit.bayesglm,
                          bstTree=fit.bstTree,
                          glm = fit.glm,
                          nb=fit.nb,
                          mlp=fit.mlp))

summary(results)
# compare accuracy of models
dotplot(results)

# summarize Best Model
print(fit.lda)
print(fit.cart)
print(fit.cart2)
print(fit.knn)
print(fit.svm)
print(fit.rf)
print(fit.bayesglm)
print(fit.bstTree)
print(fit.nb)
print(fit.mlp)
print(fit.glm)

ggplot(fit.lda)+theme_bw()+ggtitle("LDA Model: Accuracy vs Discriminant Funtions")+theme(plot.title = element_text(hjust = 0.5))
ggsave("LDA Model Accuracy vs Discriminant Funtions.png", width = 5, height = 5)

ggplot(fit.cart) + theme_bw()+ggtitle("CART Model: Accuracy vs Complexity Parameter ")+theme(plot.title = element_text(hjust = 0.5))
ggsave("CART Model Accuracy vs Complexity Parameter .png", width = 5, height = 5)

ggplot(fit.cart2) + theme_bw()+ggtitle("CART2 Model: Accuracy vs Max Tree Depth")+theme(plot.title = element_text(hjust = 0.5))
ggsave("CART2 Model Accuracy vs Max Tree Depth.png", width = 5, height = 5)

ggplot(fit.knn) + theme_bw()+ggtitle("KNN Model: Accuracy vs Number of Neigbors")+theme(plot.title = element_text(hjust = 0.5))
ggsave("KNN Model Accuracy vs Number of Neigbors.png", width = 5, height = 5)

ggplot(fit.rf) + theme_bw()+ggtitle("Random Forest Model: Accuracy vs Number of Randomly Selected Predictors")+theme(plot.title = element_text(hjust = 0.5))
ggsave("Random Forest Model Accuracy vs Number of Randomly Selected Predictors.png", width = 5, height = 5)

ggplot(fit.mlp) + theme_bw()+ggtitle("MLP Model: Accuracy vs Number of Hidden Units")+theme(plot.title = element_text(hjust = 0.5))
ggsave("MLP Model Accuracy vs Number of Hidden Units.png", width = 5, height = 5)

#need to try log scale
ggplot(fit.glm) + theme_bw()+ggtitle("GLM Model: Accuracy vs Weight Decay")+theme(plot.title = element_text(hjust = 0.5))
ggsave("GLM Model Accuracy vs Weight Decay.png", width = 5, height = 5)

ggplot(fit.svm, aes(sigma,Accuracy)) + theme_bw()+ggtitle("SVM Model: Accuracy vs Sigma")+theme(plot.title = element_text(hjust = 0.5))
ggsave("SVM Model Accuracy vs Sigma.png", width = 5, height = 5)

ggplot(fit.bstTree) + theme_bw()+ggtitle("Boosted Tree Model: Accuracy vs Boosting Iterations")+theme(plot.title = element_text(hjust = 0.5))
ggsave("Boosted Tree Model Accuracy vs Boosting Iterations.png", width = 5, height = 5)

ggplot(fit.nb)+ theme_bw()+ggtitle("Naive Bayes Model: Accuracy vs Laplace Correlations")+theme(plot.title = element_text(hjust = 0.5))
ggsave("Naive Bayes Model Accuracy vs Laplace Correlations.png", width = 5, height = 5)


write.csv(fit.lda[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Nb_Results.csv", row.names = TRUE)
write.csv(fit.cart[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Cart_Results.csv", row.names = TRUE)
write.csv(fit.cart2[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Cart2_Results.csv", row.names = TRUE)
write.csv(fit.knn[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Knn_Results.csv", row.names = TRUE)
write.csv(fit.rf[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Rf_Results.csv", row.names = TRUE)
write.csv(fit.mlp[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Mlp_Results.csv", row.names = TRUE)
write.csv(fit.glm[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Glm_Results.csv", row.names = TRUE)
write.csv(fit.svm[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Svm_Results.csv", row.names = TRUE)
write.csv(fit.bstTree[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\bstTree_Results.csv", row.names = TRUE)
write.csv(fit.nb[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Nb_Results.csv", row.names = TRUE)
write.csv(fit.bayesglm[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\Bayesglm_Results.csv", row.names = TRUE)


# estimate skill of LDA on the validation dataset
predict.lda <- predict(fit.lda, validation)
confusionMatrix(predict.lda, validation$Spacing)

# estimate skill of CART on the validation dataset
predict.cart <- predict(fit.cart, validation)
confusionMatrix(predict.cart, validation$Spacing)

# estimate skill of CART2 on the validation dataset
predict.cart2 <- predict(fit.cart2, validation)
confusionMatrix(predict.cart2, validation$Spacing)

# estimate skill of KNN on the validation dataset
predict.knn <- predict(fit.knn, validation)
confusionMatrix(predict.knn, validation$Spacing)

# estimate skill of SVM on the validation dataset
predict.svm <- predict(fit.svm, validation)
confusionMatrix(predict.svm, validation$Spacing)

# estimate skill of RF on the validation dataset
predict.rf <- predict(fit.rf, validation)
confusionMatrix(predict.rf, validation$Spacing)

# estimate skill of bayesglm on the validation dataset
predict.bayesglm <- predict(fit.bayesglm, validation)
confusionMatrix(predict.bayesglm, validation$Spacing)

# estimate skill of bstTree on the validation dataset
predict.bstTree <- predict(fit.bstTree, validation)
confusionMatrix(predict.bstTree, validation$Spacing)

# estimate skill of mlp on the validation dataset
predict.mlp <- predict(fit.mlp, validation)
confusionMatrix(predict.mlp, validation$Spacing)

# estimate skill of glm on the validation dataset
predict.glm <- predict(fit.glm, validation)
confusionMatrix(predict.glm, validation$Spacing)




