library(caret)
library(arm)
library(mboost)
library(klaR)
library (ipred)
library(nnet)
library(writexl)
library(readr)
Identification <- read_csv("Gender_Identification_IET_talk.csv")
View(Identification)
# rename the dataset
dataset <- Identification[-c(1)]
View(Identification)
View(dataset)
View(dataset)
predict <- dateset[c(8)]
#
# # define the filename
# filename <- "iris.csv"
#
# # load the CSV file from the local directory
# dataset <- read.csv(filename, header=FALSE)
#
# # set the column names in the dataset
# colnames(dataset) <- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
predict <- dataset[c(8)]
View(predict)
validation_index <- createDataPartition(dataset$Spacing, p=0.80, list=FALSE)
# select 20% of the data for validation
validation <- dataset[-validation_index,]
# use the remaining 80% of data to training and testing the models
dataset <- dataset[validation_index,]
#dimension of dataset
dim(dataset) #120 instances (rows) 5 attributes (column)
# list types for each attribute
sapply(dataset, class) #factor is nominal data. levels. ranking.
control <- trainControl(method="cv", number=10)
metric <- c("Accuracy")
set.seed(100)
tunegridlda= expand.grid(dimen=c(0:5))
fit.lda <- train(predict,
data=dataset,
method="lda2",
tuneGrid= tunegridlda,
metric=metric,
trControl=control)
set.seed(100)
#tunegridcart= expand.grid(cp=c(seq(0, 1, by=0.05)))
fit.cart <- train(predict,
data=dataset,
method="rpart",
tuneGrid = tunegridcart,
metric=metric,
trControl=control)
summary(dataset)
set.seed(100)
tunegridknn= expand.grid(k=c(1:50))
fit.knn <- train(predict,
data=dataset,
method="knn",
metric=metric,
# tuneGrid= tunegridknn,
trControl=control)
#
# # define the filename
# filename <- "iris.csv"
#
# # load the CSV file from the local directory
# dataset <- read.csv(filename, header=FALSE)
#
# # set the column names in the dataset
# colnames(dataset) <- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
predict <- Gender based on answers~.
Identification <- read_csv("Gender_Identification_IET_talk.csv")
#View(Identification)
# attach the iris dataset to the environment
#data(Identification)
# rename the dataset
dataset <- Identification[-c(1)]
#
# # define the filename
# filename <- "iris.csv"
#
# # load the CSV file from the local directory
# dataset <- read.csv(filename, header=FALSE)
#
# # set the column names in the dataset
# colnames(dataset) <- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
predict <- Gender~.
predict <- Gender~.
# create a list of 80% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(dataset$Gender, p=0.80, list=FALSE)
# select 20% of the data for validation
validation <- dataset[-validation_index,]
# use the remaining 80% of data to training and testing the models
dataset <- dataset[validation_index,]
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- c("Accuracy")
set.seed(100)
tunegridknn= expand.grid(k=c(1:50))
fit.knn <- train(predict,
data=dataset,
method="knn",
metric=metric,
# tuneGrid= tunegridknn,
trControl=control)
set.seed(100)
#tunegridcart2= expand.grid(maxdepth=c(0:5))
fit.cart2 <- train(predict,
data=dataset,
method="rpart2",
#tuneGrid = tunegridcart2,
metric=metric,
trControl=control)
set.seed(100)
#tunegridSVM = expand.grid(sigma= 2^c(-25, -20, -15,-10, -5, 0), C=3**(-7:7))
fit.svm <- train(predict,
data=dataset,
method="svmRadial",
metric=metric,
#tuneGrid = tunegridSVM,
trControl=control)
set.seed(100)
tunegridRF = expand.grid(mtry = seq(0, 200, by=1))
fit.rf <- train(predict, data=dataset,
method="rf",
metric = metric,
tuneGrid = tunegridRF,
trControl = control)
print(fit.rf)
# estimate skill of RF on the validation dataset
predict.rf <- predict(fit.rf, validation)
(predict.rf, validation$Gender)
predict.rf
predict.rf <- predict(fit.rf, dataset)
library(caret)
library(arm)
library(mboost)
library(klaR)
library (ipred)
library(nnet)
library(writexl)
library(readr)
Identification <- read_csv("Gender_Identification_IET_talk.csv")
#View(Identification)
# attach the iris dataset to the environment
#data(Identification)
# rename the dataset
dataset <- Identification[-c(1)]
#
# # define the filename
# filename <- "iris.csv"
#
# # load the CSV file from the local directory
# dataset <- read.csv(filename, header=FALSE)
#
# # set the column names in the dataset
# colnames(dataset) <- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
predict <- Gender~.
# create a list of 80% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(dataset$Gender, p=0.80, list=FALSE)
# select 20% of the data for validation
validation <- dataset[-validation_index,]
# use the remaining 80% of data to training and testing the models
dataset <- dataset[validation_index,]
#dimension of dataset
dim(dataset) #120 instances (rows) 5 attributes (column)
# list types for each attribute
sapply(dataset, class) #factor is nominal data. levels. ranking.
# take a peek at the first 5 rows of the data
head(dataset)
tail(dataset)
# list the levels for the class
#levels(dataset$Gender)
# summarize the class distribution
percentage <- prop.table(table(dataset$Gender)) * 100
cbind(freq=table(dataset$Gender), percentage=percentage)
summary(dataset)
#split numeric and factor. input and target
x <- dataset[,1:4]
y <- dataset[,5]
# boxplot for each attribute on one image
par(mfrow=c(1,9))
for(i in 1:9) {
boxplot(x[,i], main=names(Identification)[i])
}
par(mfrow = c(1,1))
plot(y)
# scatterplot matrix
featurePlot(x=x, y=y, plot="ellipse")
# box and whisker plots for each attribute
featurePlot(x=x, y=y, plot="box")
# density plots for each attribute by class value
scales <- list(x=list(relation="free"), y=list(relation="free"))
featurePlot(x=x, y=y, plot="density", scales=scales)
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- c("Accuracy")
# Random Forest
set.seed(100)
tunegridRF = expand.grid(mtry = seq(0, 200, by=1))
fit.rf <- train(predict, data=dataset,
method="rf",
metric = metric,
tuneGrid = tunegridRF,
trControl = control)
#############################################################################################################
#############################################################################################################
#summarize accuracy of models
results <- resamples(list(
rf=fit.rf
))
summary(results)
# summarize Best Model
print(fit.rf)
ggplot(fit.rf) + theme_bw()+ggtitle("Random Forest Model: Accuracy vs Number of Randomly Selected Predictors")+theme(plot.title = element_text(hjust = 0.5))
ggsave("Random Forest Model Accuracy vs Number of Randomly Selected Predictors.png", width = 5, height = 5)
write.csv(fit.rf[["results"]],"C:\\Users\\User\\Google Drive\\Master Syahmi\\5G\\PHD\\Subcarrier Prediction\\Machine learning subcarrier prediction2\\subcarrier prediction\\IET_Rf_Results.csv", row.names = TRUE)
# estimate skill of RF on the validation dataset
predict.rf <- predict(fit.rf, validation)
confusionMatrix(predict.rf, validation$Gender)
predict.rf <- predict(fit.rf, dataset)
print(predict.rf)
append<- as.data.frame(predict.rf)
final <- cbind(dataset,append)
View(final)
